{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6bee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "kentarrito/AI-Scientist-Fork\n",
    "Add brainstorming mechanism in idea generation part\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbde7f2",
   "metadata": {},
   "source": [
    "# Step 1 : Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2468ae1d",
   "metadata": {},
   "source": [
    "## Process Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c1d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Model from local environment\n",
    "\n",
    "import asyncio\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import AsyncLLMEngine, AsyncEngineArgs, SamplingParams\n",
    "import time, warnings\n",
    "\n",
    "model_name = \"deepseek_r1_qwen14b\"\n",
    "tensor_parallel_size = 2\n",
    "\n",
    "engine_args = AsyncEngineArgs(\n",
    "    model = model_name,\n",
    "    tensor_parallel_size = tensor_parallel_size,\n",
    "    gpu_memory_utilization=0.95,\n",
    ")\n",
    "engine = AsyncLLMEngine.from_engine_args(engine_args)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')\n",
    "\n",
    "\n",
    "class AllRequests:\n",
    "    \n",
    "    def __init__(self, max_request):\n",
    "        self.max_request = max_request\n",
    "        self.requests = []\n",
    "        self.request_ids = []\n",
    "        self.request_id = 0\n",
    "        self.results = []\n",
    "        self.finished_ids = []\n",
    "        \n",
    "    def add(self, request):\n",
    "        self.requests.append(request)\n",
    "        self.request_ids.append(self.request_id)\n",
    "        self.request_id += 1\n",
    "    \n",
    "    async def process(self, model=model_name, max_tokens = 3000, temperature=0.4, save_dir = \"progress_log\", restart = False):\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        if restart:\n",
    "            if os.path.exists(f\"{save_dir}/finished_ids.json\") and os.path.exists(f\"{save_dir}/results.json\"):\n",
    "                with open(f\"{save_dir}/finished_ids.json\") as f:\n",
    "                    finished_ids = json.load(f)\n",
    "                with open(f\"{save_dir}/results.json\") as f:\n",
    "                    self.results = json.load(f)\n",
    "                for finished_id in finished_ids:\n",
    "                    self.finished_ids.append(finished_id)\n",
    "                    id = self.request_ids.index(finished_id)\n",
    "                    self.request_ids.pop(id)\n",
    "                    self.requests.pop(id)\n",
    "\n",
    "        await asyncio.gather(\n",
    "            *[self.process_requests(temperature = temperature, max_tokens = max_tokens, restart = restart, save_dir=save_dir) for _ in range(self.max_request)]\n",
    "        )\n",
    "            \n",
    "        return self.results\n",
    "\n",
    "\n",
    "    async def process_requests(self, max_tokens = 3000, temperature=0.4, save_dir = \"progress_log\", restart = False):\n",
    "\n",
    "        while len(self.requests) != 0:\n",
    "            request_dict = self.requests.pop(0)\n",
    "            request_id = self.request_ids.pop(0)\n",
    "\n",
    "            prompt = request_dict[\"prompt\"]\n",
    "\n",
    "            final_output = None\n",
    "            results_generator = engine.generate(prompt, SamplingParams(temperature=temperature, max_tokens=max_tokens), request_id)\n",
    "            async for request_output in results_generator:\n",
    "                # print(request_output) => for streaming\n",
    "                final_output = request_output\n",
    "\n",
    "            output = final_output.outputs[0].text\n",
    "            \n",
    "            request_dict[\"output\"] = output\n",
    "            self.results.append(request_dict)\n",
    "            self.finished_ids.append(request_id)\n",
    "\n",
    "            with open(f\"{save_dir}/results.json\", \"w\") as f:\n",
    "                json.dump(self.results, f)\n",
    "            with open(f\"{save_dir}/finished_ids.json\", \"w\") as f:\n",
    "                json.dump(self.finished_ids, f)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d38273",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a3f971",
   "metadata": {},
   "source": [
    "## Solve Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383cfe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE IDEAS\n",
    "def generate_bs_agents_dataset(\n",
    "        base_dir,\n",
    "        agents,\n",
    "        client,\n",
    "        model,\n",
    "        skip_generation=False,\n",
    "        max_num_generations=20,\n",
    "        num_reflections=5,\n",
    "):\n",
    "    if skip_generation:\n",
    "        # Load existing ideas from file\n",
    "        try:\n",
    "            with open(osp.join(base_dir, \"ideas.json\"), \"r\") as f:\n",
    "                ideas = json.load(f)\n",
    "            print(\"Loaded existing ideas:\")\n",
    "            for idea in ideas:\n",
    "                print(idea)\n",
    "            return ideas\n",
    "        except FileNotFoundError:\n",
    "            print(\"No existing ideas found. Generating new ideas.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error decoding existing ideas. Generating new ideas.\")\n",
    "\n",
    "    idea_str_archive = []\n",
    "    with open(osp.join(base_dir, \"seed_ideas.json\"), \"r\") as f:\n",
    "        seed_ideas = json.load(f)\n",
    "    for seed_idea in seed_ideas:\n",
    "        idea_str_archive.append(json.dumps(seed_idea))\n",
    "\n",
    "    with open(osp.join(base_dir, \"experiment.py\"), \"r\") as f:\n",
    "        code = f.read()\n",
    "\n",
    "    with open(osp.join(base_dir, \"prompt.json\"), \"r\") as f:\n",
    "        prompt = json.load(f)\n",
    "\n",
    "    idea_system_prompt = prompt[\"system\"]\n",
    "\n",
    "    \n",
    "    \n",
    "    bs_msg_histories = {}  # {(depth,branch):[{\"system\":}...], ...}\n",
    "    bs_agent_id_histories = {}  # {(depth,branch):id, ...}\n",
    "    all_ideas = {}\n",
    "\n",
    "    num_depth = 2\n",
    "    num_branch = 2\n",
    "    n_agents = len(agents)\n",
    "    bs_agent_tree = {}  # [{\"agent_id\":, \"node_id\":[0], \"bs_msg\":[{\"role\":\"system\", \"content\":\"...\"}], \"ideas\":[{}], \"children\":[{\"msg\":[{\"role\":\"user\"}, {\"role\":\"assistant\"}]}]}, ]\n",
    "\n",
    "    def build_bs_agent_tree(agents, *, num_depth=3, num_branch=2, seed=None):\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        if not agents:\n",
    "            raise ValueError(\"agents list is empty.\")\n",
    "\n",
    "        n_agents = len(agents)\n",
    "\n",
    "        def _grow(node, depth, forbidden):\n",
    "            if depth == num_depth:\n",
    "                return\n",
    "            available = list(set(range(n_agents)) - forbidden)\n",
    "            if not available:\n",
    "                raise RuntimeError(\"Not enough distinct agents for the depth requested.\")\n",
    "\n",
    "            picked_a_idxs = random.sample(available, num_branch)\n",
    "            for b in range(num_branch):\n",
    "                a_idx = picked_a_idxs[b]\n",
    "                child = {\n",
    "                    \"agent\"   : agents[a_idx],\n",
    "                    \"agent_ids\": node[\"agent_ids\"] + [a_idx],\n",
    "                    \"agent_id\": a_idx,\n",
    "                    \"node_ids\" : node[\"node_ids\"] + [b],\n",
    "                    \"bs_msg\"  : [],\n",
    "                    \"ideas\"   : [],\n",
    "                    \"children\": [],\n",
    "                }\n",
    "                node[\"children\"].append(child)\n",
    "\n",
    "                _grow(child, depth + 1, forbidden | {a_idx})\n",
    "\n",
    "        root = {\"agent_id\": None, \"agent_ids\": [], \"node_ids\": [], \"bs_msg\": [], \"ideas\": [], \"children\": []}\n",
    "        _grow(root, 0, set())\n",
    "        return root\n",
    "\n",
    "    def get_assistant_msg(\n",
    "        node,\n",
    "        *,                          # keyword-only\n",
    "        history_so_far,             # ancestor conversation\n",
    "        prompt, code,\n",
    "        client, model,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Returns a *new* history list that is `history_so_far`\n",
    "        plus ONE user/assistant pair for this depth,\n",
    "        and the parsed idea dict produced in that exchange.\n",
    "        \"\"\"\n",
    "        if node[\"agent_ids\"]==[]: agent_id = None\n",
    "        else: agent_id = node[\"agent_ids\"][-1]\n",
    "\n",
    "        # ------------------------------------------------------------------ copy\n",
    "        bs_msg = list(history_so_far)               # preserves ancestor msgs\n",
    "\n",
    "        # --------------------------------------------------- construct user turn\n",
    "\n",
    "        bs_sys_msg = brainstorming_system_msg.format(\n",
    "            task_description = prompt[\"task_description\"],\n",
    "            code             = code,\n",
    "        )\n",
    "\n",
    "        bs_prompt = brainstorming_prompt.format(\n",
    "            agent = agents[agent_id],\n",
    "        )\n",
    "\n",
    "        bs_txt, bs_msg = get_response_from_llm(\n",
    "            bs_prompt,\n",
    "            client         = client,\n",
    "            model          = model,\n",
    "            system_message = bs_sys_msg,\n",
    "            msg_history    = bs_msg,\n",
    "        )\n",
    "\n",
    "        idea_prompt = idea_first_prompt.format(\n",
    "            task_description = prompt[\"task_description\"],\n",
    "            code             = code,\n",
    "            num_reflections  = num_reflections,\n",
    "        )\n",
    "\n",
    "        # talk to LLM *once* (temp_history is a throw-away list)\n",
    "        idea_txt, msg_history = get_response_from_llm(\n",
    "            idea_prompt,\n",
    "            client         = client,\n",
    "            model          = model,\n",
    "            system_message = \"\",\n",
    "            msg_history    = bs_msg,\n",
    "        )\n",
    "\n",
    "        # Iteratively improve task.\n",
    "        if num_reflections > 1:\n",
    "            msg_history = msg_history[-2:]\n",
    "            for j in range(num_reflections - 1):\n",
    "                idea_txt, msg_history = get_response_from_llm(\n",
    "                    idea_reflection_prompt.format(\n",
    "                        current_round=j + 2, num_reflections=num_reflections\n",
    "                    ),\n",
    "                    client=client,\n",
    "                    model=model,\n",
    "                    system_message=idea_system_prompt,\n",
    "                    msg_history=msg_history,\n",
    "                )\n",
    "                ## PARSE OUTPUT\n",
    "                json_output = extract_json_between_markers(idea_txt)\n",
    "                assert (\n",
    "                        json_output is not None\n",
    "                ), \"Failed to extract JSON from LLM output\"\n",
    "                #print()\n",
    "                #print(f\"Iteration {j + 2}/{num_reflections} Generated Ideas: \")\n",
    "                #print(json_output)\n",
    "\n",
    "                if \"I am done\" in idea_txt:\n",
    "                    #print()\n",
    "                    #print(f\"Idea generation converged after {j + 2} iterations.\")\n",
    "                    break\n",
    "\n",
    "\n",
    "        # parse idea\n",
    "        idea_json = extract_json_between_markers(idea_txt) or {\"idea\": idea_txt,\n",
    "                                                                    \"agent\": agents[agent_id]}\n",
    "        return bs_msg, [idea_json]\n",
    "\n",
    "    total_num_node = num_branch**(num_depth+1) - 2\n",
    "\n",
    "    global populate_count\n",
    "    populate_count = 0\n",
    "    def populate_tree(node, history_so_far, **llm_kwargs):\n",
    "        global populate_count\n",
    "        \"\"\"\n",
    "        Depth-first traversal.\n",
    "        history_so_far already obeys the 1 + depth*2 rule.\n",
    "        \"\"\"\n",
    "        if node[\"agent_id\"] is not None:         # skip dummy root\n",
    "            node[\"bs_msg\"], node[\"ideas\"] = get_assistant_msg(\n",
    "                node,\n",
    "                history_so_far = history_so_far,\n",
    "                **llm_kwargs,\n",
    "            )\n",
    "            next_history = node[\"bs_msg\"]\n",
    "            populate_count += 1\n",
    "            print(f\"populate count: {populate_count}/{total_num_node}\")\n",
    "        else:\n",
    "            next_history = history_so_far\n",
    "\n",
    "        for child in node[\"children\"]:\n",
    "            populate_tree(child, next_history, **llm_kwargs)\n",
    "\n",
    "    print()\n",
    "    print(\"Making Brainstorming Tree...\")\n",
    "    print(f\"num_depth:{num_depth}, num_branch:{num_branch}, n_agents:{n_agents}, \")\n",
    "\n",
    "    bs_agent_tree = build_bs_agent_tree(\n",
    "        agents, num_depth=num_depth, num_branch=num_branch, seed=42\n",
    "    )\n",
    "\n",
    "    print(bs_agent_tree)\n",
    "\n",
    "    print()\n",
    "    print(\"Brainstorming and Genrating Ideas...\")\n",
    "\n",
    "    populate_tree(\n",
    "        bs_agent_tree,\n",
    "        history_so_far = [],      # start empty\n",
    "        prompt         = prompt,\n",
    "        code           = code,\n",
    "        client         = client,\n",
    "        model          = model,\n",
    "    )\n",
    "\n",
    "    ## SAVE IDEAS\n",
    "\n",
    "    with open(osp.join(base_dir, \"bs_agent_tree.json\"), \"w\") as f:\n",
    "        json.dump(bs_agent_tree, f, indent=4)\n",
    "\n",
    "    return bs_agent_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc92ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_idea_novelty_in_bs_agent_tree(\n",
    "    bs_agent_tree,  # {\"agent_ids\":[],\"bs_msg\":[],\"children\":[{same structure}, ]}\n",
    "    base_dir,\n",
    "    client,\n",
    "    model,\n",
    "    max_num_iterations=10,\n",
    "    engine=\"semanticscholar\",\n",
    "):\n",
    "    with open(osp.join(base_dir, \"experiment.py\"), \"r\") as f:\n",
    "        code = f.read()\n",
    "    with open(osp.join(base_dir, \"prompt.json\"), \"r\") as f:\n",
    "        prompt = json.load(f)\n",
    "        task_description = prompt[\"task_description\"]\n",
    "\n",
    "    def check(ideas):\n",
    "        idea = ideas[0]\n",
    "\n",
    "        print(f\"\\nChecking novelty of idea: {idea['Name']}\")\n",
    "        \n",
    "        novel = False\n",
    "        msg_history = []\n",
    "        papers_str = \"\"\n",
    "        thought_output = \"\"\n",
    "\n",
    "        for j in range(max_num_iterations):\n",
    "            try:\n",
    "                text, msg_history = get_response_from_llm(\n",
    "                    novelty_prompt.format(\n",
    "                        current_round=j + 1,\n",
    "                        num_rounds=max_num_iterations,\n",
    "                        idea=idea,\n",
    "                        last_query_results=papers_str,\n",
    "                    ),\n",
    "                    client=client,\n",
    "                    model=model,\n",
    "                    system_message=novelty_system_msg.format(\n",
    "                        num_rounds=max_num_iterations,\n",
    "                        task_description=task_description,\n",
    "                        code=code,\n",
    "                    ),\n",
    "                    msg_history=msg_history,\n",
    "                )\n",
    "                thought_output = extract_text_inside_backticks(text, \"thought\") or thought_output\n",
    "\n",
    "                if \"decision made: novel\" in text.lower():\n",
    "                    print(\"Decision made: novel after round\", j)\n",
    "                    novel = True\n",
    "                    break\n",
    "                if \"decision made: not novel\" in text.lower():\n",
    "                    print(\"Decision made: not novel after round\", j)\n",
    "                    break\n",
    "\n",
    "                # parse JSON\n",
    "                json_output = extract_json_between_markers(text)\n",
    "                assert json_output is not None, \"Failed to extract JSON from LLM output\"\n",
    "\n",
    "                # search\n",
    "                query = json_output.get(\"Query\", \"\")\n",
    "                papers = search_for_papers(query, result_limit=5, engine=engine)\n",
    "                if not papers:\n",
    "                    papers_str = \"No papers found.\"\n",
    "                else:\n",
    "                    paper_strings = []\n",
    "                    for i, paper in enumerate(papers):\n",
    "                        paper_strings.append(\n",
    "                                \"\"\"{i}: {title}. {authors}. {venue}, {year}.\\nNumber of citations: {cites}\\nAbstract: {abstract}\"\"\".format(\n",
    "                                    i=i,\n",
    "                                    title=paper[\"title\"],\n",
    "                                    authors=paper[\"authors\"],\n",
    "                                    venue=paper[\"venue\"],\n",
    "                                    year=paper[\"year\"],\n",
    "                                    cites=paper[\"citationCount\"],\n",
    "                                    abstract=paper[\"abstract\"],\n",
    "                                )\n",
    "                        )\n",
    "                    papers_str = \"\\n\\n\".join(paper_strings)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                continue\n",
    "\n",
    "        print()\n",
    "        print(f\"novelty: {novel}\")\n",
    "\n",
    "        return [novel]\n",
    "\n",
    "\n",
    "    def add_novelty_to_tree(node, depth):\n",
    "\n",
    "        if node[\"children\"] == []:\n",
    "            return None\n",
    "\n",
    "        else:\n",
    "            for i, node_dict in enumerate(node[\"children\"]):\n",
    "                novelties = check(node_dict[\"ideas\"])\n",
    "                node[\"children\"][i][\"novelties\"] = novelties\n",
    "\n",
    "                add_novelty_to_tree(node_dict, depth + 1)\n",
    "            \n",
    "\n",
    "    #bs_agent_tree = {\"agent_id\": None, \"agent_ids\": [], \"node_ids\": [], \"bs_msg\": [], \"ideas\": [], \"children\": []}\n",
    "    add_novelty_to_tree(bs_agent_tree, 0)\n",
    "\n",
    "    return bs_agent_tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32bfef5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Step 2 : Make dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = \"/workspace/exp12\"\n",
    "# bs_agent_tree = {\"agent_id\": None, \"agent_ids\": [], \"node_ids\": [], \"task\": \"\", \"bs_msg\": [], \"ideas\": [], \"novelty\": True or False, \"children\": [{}, ...]}\n",
    "bs_agent_tree_save_dir = \"/workspace/AI-Scientist-Fork-dataset\"\n",
    "dataset_list_save_path = f\"{exp_dir}/dataset_list.json\"\n",
    "\n",
    "import os\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcee823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def list_files(root_dir):\n",
    "    file_paths = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for fname in filenames:\n",
    "            file_paths.append(os.path.join(dirpath, fname))\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "if not os.path.exists(dataset_list_save_path):\n",
    "\n",
    "    bs_agent_trees = []\n",
    "    all_files = list_files(bs_agent_tree_save_dir)\n",
    "\n",
    "    for file_path in all_files:\n",
    "        with open(file_path) as f:\n",
    "            bs_agent_tree = json.load(f)\n",
    "\n",
    "        bs_agent_trees.append(bs_agent_tree)\n",
    "        \n",
    "\n",
    "    def get_dataset_dict(task, chosen_msg, rejected_msg):\n",
    "        if len(chosen_msg) != len(chosen_msg):\n",
    "            raise Exception(\"chosen_msg and rejected_msg must be same size\") \n",
    "\n",
    "        if len(chosen_msg) == 2:\n",
    "            return {\n",
    "                \"query\":[{'role': 'user', 'content':f\"Give me a brainstorming sentence to solve the task below;\\n\\nTask:{task}\"}],\n",
    "                \"chosen_key\":[{'role': 'assistant', 'content': chosen_msg[0][\"content\"]}],\n",
    "                \"rejected_key\":[{'role': 'assistant', 'content': rejected_msg[0][\"content\"]}],\n",
    "            }\n",
    "        elif len(chosen_msg) < 2:\n",
    "            return None\n",
    "        else:\n",
    "            return {\n",
    "                \"query\": chosen_msg[:-2] + [{'role': 'user', 'content':f\"Give me a brainstorming sentence to solve the task below;\\n\\nTask:{task}\"}],\n",
    "                \"chosen_key\": [{'role': 'assistant', 'content': chosen_msg[-2][\"content\"]}],\n",
    "                \"rejected_key\": [{'role': 'assistant', 'content': rejected_msg[-2][\"content\"]}],\n",
    "            }\n",
    "\n",
    "\n",
    "    dataset_list = []\n",
    "    def walk(node, depth):\n",
    "        global dataset_list\n",
    "\n",
    "        if node[\"children\"] == []:\n",
    "            return 0\n",
    "\n",
    "        else:\n",
    "            num_novel = 0\n",
    "            updated_score = 0\n",
    "            scores = []\n",
    "            bs_msgs = []\n",
    "            for i, node_dict in enumerate(node[\"children\"]):\n",
    "                #dataset_dict = get_dataset_dict(node_dict)\n",
    "                bs_msg = node_dict[\"bs_msg\"]  # [{\"role\":}, ...]\n",
    "                task = node_dict[\"task\"]\n",
    "                novelty = node_dict[\"novelty\"]\n",
    "                score = walk(node_dict, depth + 1)\n",
    "                if novelty: score += 1\n",
    "                updated_score += score\n",
    "\n",
    "                for j, other_score in enumerate(scores):\n",
    "                    if score < other_score:\n",
    "                        dataset_dict = get_dataset_dict(task, chosen_msg=bs_msgs[j], rejected_msg=bs_msg)\n",
    "                    elif score > other_score:\n",
    "                        dataset_dict = get_dataset_dict(task, chosen_msg=bs_msg, rejected_msg=bs_msgs[j])\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    dataset_list.append(dataset_dict)\n",
    "\n",
    "                    \n",
    "                bs_msgs.append(bs_msg)\n",
    "                scores.append(score)\n",
    "\n",
    "            updated_score = updated_score / len(node[\"children\"])\n",
    "\n",
    "        return update_score\n",
    "\n",
    "    for bs_agent_tree in bs_agent_trees:\n",
    "        walk(bs_agent_tree, 0)\n",
    "\n",
    "    with open(dataset_list_save_path, \"w\") as f:\n",
    "        json.dump(dataset_list, f)\n",
    "        \n",
    "else:\n",
    "    with open(dataset_list_save_path) as f:\n",
    "        dataset_list = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d60cb68",
   "metadata": {},
   "source": [
    "# Step 3 : Train Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c845d0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0578ac074b514a20b053bbe67cc43ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rmsearch import RMTrainer\n",
    "\n",
    "model_name = \"/workspace/llama3b-rm\"\n",
    "num_gpus = 1\n",
    "\n",
    "rmtrainer = RMTrainer(model_name = model_name, num_gpus = num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85889110",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_save_path = f\"{exp_dir}/dataset\"\n",
    "train_ids_save_path = f\"{exp_dir}/train_ids.json\"\n",
    "test_ids_save_path = f\"{exp_dir}/test_ids.json\"\n",
    "test_size = 48\n",
    "\n",
    "formatted_dataset = rmtrainer.prepare_dataset(dataset_list, dataset_save_path, test_size, train_ids_save_path, test_ids_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9b497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> chosen_text                                   </span>┃<span style=\"font-weight: bold\"> rejected_text                                </span>┃<span style=\"font-weight: bold\"> logits           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ &lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|… │ &lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;… │ [0.4907, 0.5093] │\n",
       "│                                               │                                              │                  │\n",
       "│ Cutting Knowledge Date: December 2023         │ Cutting Knowledge Date: December 2023        │                  │\n",
       "│ Today Date: 07 May 2025                       │ Today Date: 07 May 2025                      │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ &lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_heade… │ &lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_head… │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Give me an advice to the problem and answer   │ Give me an advice to the problem and answer  │                  │\n",
       "│ below;                                        │ below;                                       │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Problem:Train a logistic regression model on  │ Problem:Train a logistic regression model on │                  │\n",
       "│ one feature and evaluate its performance      │ one feature and evaluate its performance     │                  │\n",
       "│ using a confusion matrix plot. The function   │ using a confusion matrix plot. The function  │                  │\n",
       "│ takes a feature and a target series, splits   │ takes a feature and a target series, splits  │                  │\n",
       "│ them into training and testing sets, trains   │ them into training and testing sets, trains  │                  │\n",
       "│ the logistic regression model, predicts the   │ the logistic regression model, predicts the  │                  │\n",
       "│ target for the test set, and plots the        │ target for the test set, and plots the       │                  │\n",
       "│ confusion matrix.                             │ confusion matrix.                            │                  │\n",
       "│ The function should output with:              │ The function should output with:             │                  │\n",
       "│     (np.ndarray, plt.Axes): A tuple           │     (np.ndarray, plt.Axes): A tuple          │                  │\n",
       "│ containing the confusion matrix and the       │ containing the confusion matrix and the      │                  │\n",
       "│ matplotlib Axes object of the confusion       │ matplotlib Axes object of the confusion      │                  │\n",
       "│ matrix plot.                                  │ matrix plot.                                 │                  │\n",
       "│ You should write self-contained code starting │ You should write self-contained code         │                  │\n",
       "│ with:                                         │ starting with:                               │                  │\n",
       "│ ```                                           │ ```                                          │                  │\n",
       "│ import pandas as pd                           │ import pandas as pd                          │                  │\n",
       "│ from sklearn.model_selection import           │ from sklearn.model_selection import          │                  │\n",
       "│ train_test_split                              │ train_test_split                             │                  │\n",
       "│ from sklearn.linear_model import              │ from sklearn.linear_model import             │                  │\n",
       "│ LogisticRegression                            │ LogisticRegression                           │                  │\n",
       "│ from sklearn.metrics import confusion_matrix  │ from sklearn.metrics import confusion_matrix │                  │\n",
       "│ import numpy as np                            │ import numpy as np                           │                  │\n",
       "│ import matplotlib.pyplot as plt               │ import matplotlib.pyplot as plt              │                  │\n",
       "│ def task_func(feature: pd.Series, target:     │ def task_func(feature: pd.Series, target:    │                  │\n",
       "│ pd.Series) -&gt; (np.ndarray, plt.Axes):         │ pd.Series) -&gt; (np.ndarray, plt.Axes):        │                  │\n",
       "│ ```                                           │ ```                                          │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Answer:&lt;think&gt;                                │ Answer:&lt;think&gt;                               │                  │\n",
       "│ Okay, I need to write a Python function       │ Okay, I need to write a Python function      │                  │\n",
       "│ called task_func that takes a feature and a   │ called task_func that takes a feature and a  │                  │\n",
       "│ target as inputs and returns a tuple          │ target as inputs and returns a tuple         │                  │\n",
       "│ containing a confusion matrix and a           │ containing a confusion matrix and a          │                  │\n",
       "│ matplotlib Axes object. The function should   │ matplotlib Axes object. The function should  │                  │\n",
       "│ train a logistic regression model on one      │ train a logistic regression model on one     │                  │\n",
       "│ feature and evaluate its performance using a  │ feature and evaluate its performance using a │                  │\n",
       "│ confusion matrix plot.                        │ confusion matrix plot.                       │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ First, I should think about the steps         │ First, I should think about the steps        │                  │\n",
       "│ involved. Let's break it down.                │ involved. Let's break it down.               │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ The function starts by importing necessary    │ The function starts by importing necessary   │                  │\n",
       "│ libraries, which are already provided. So I   │ libraries, which are already provided. So I  │                  │\n",
       "│ don't need to worry about that.               │ don't need to worry about that.              │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ The first step is to split the feature and    │ The first step is to split the feature and   │                  │\n",
       "│ target into training and testing sets. I      │ target into training and testing sets. I     │                  │\n",
       "│ remember that the train_test_split function   │ remember that the train_test_split function  │                  │\n",
       "│ from sklearn can do this. So I'll use that.   │ from sklearn can do this. So I'll use that.  │                  │\n",
       "│ The feature is a pandas Series, so I need to  │ The feature is a pandas Series, so I need to │                  │\n",
       "│ convert it into a DataFrame or maybe just an  │ convert it into a DataFrame or maybe just an │                  │\n",
       "│ array? Wait, no. Wait, the feature is a       │ array? Wait, no. Wait, the feature is a      │                  │\n",
       "│ single feature, right? So when I split, I can │ single feature, right? So when I split, I    │                  │\n",
       "│ pass the feature as X and target as y.        │ can pass the feature as X and target as y.   │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Wait, but train_test_split expects X and y to │ Wait, but train_test_split expects X and y   │                  │\n",
       "│ be arrays. So for the feature, perhaps I      │ to be arrays. So for the feature, perhaps I  │                  │\n",
       "│ should convert the pd.Series into a numpy     │ should convert the pd.Series into a numpy    │                  │\n",
       "│ array. Because when I pass a Series to        │ array. Because when I pass a Series to       │                  │\n",
       "│ train_test_split, it might work, but          │ train_test_split, it might work, but         │                  │\n",
       "│ sometimes it's better to convert it to a      │ sometimes it's better to convert it to a     │                  │\n",
       "│ numpy array. Alternatively, I can reshape it  │ numpy array. Alternatively, I can reshape it │                  │\n",
       "│ into a 2D array since scikit-learn expects 2D │ into a 2D array since scikit-learn expects   │                  │\n",
       "│ for features.                                 │ 2D for features.                             │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Wait, the feature is a single feature, so     │ Wait, the feature is a single feature, so    │                  │\n",
       "│ it's a 1D array. So when I pass it to         │ it's a 1D array. So when I pass it to        │                  │\n",
       "│ train_test_split, I need to make sure it's in │ train_test_split, I need to make sure it's   │                  │\n",
       "│ the correct shape. So perhaps I should        │ in the correct shape. So perhaps I should    │                  │\n",
       "│ reshape it into a 2D array with shape         │ reshape it into a 2D array with shape        │                  │\n",
       "│ (n_samples, 1). Because LogisticRegression    │ (n_samples, 1). Because LogisticRegression   │                  │\n",
       "│ can handle that.                              │ can handle that.                             │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ So, for X, I'll take                          │ So, for X, I'll take                         │                  │\n",
       "│ feature.values.reshape(-1, 1), and y is       │ feature.values.reshape(-1, 1), and y is      │                  │\n",
       "│ target.values.                                │ target.values.                               │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Then, split them into training and testing    │ Then, split them into training and testing   │                  │\n",
       "│ sets. I can set a random state for            │ sets. I can set a random state for           │                  │\n",
       "│ reproducibility, but it's not specified, so   │ reproducibility, but it's not specified, so  │                  │\n",
       "│ maybe I can leave it out or set it to a       │ maybe I can leave it out or set it to a      │                  │\n",
       "│ specific value like 42 for consistency.       │ specific value like 42 for consistency.      │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Next, I need to train the logistic regression │ Next, I need to train the logistic           │                  │\n",
       "│ model. So I'll create an instance of          │ regression model. So I'll create an instance │                  │\n",
       "│ LogisticRegression. The default parameters    │ of LogisticRegression. The default           │                  │\n",
       "│ should be fine, but sometimes it's good to    │ parameters should be fine, but sometimes     │                  │\n",
       "│ set the solver, like 'lbfgs'. But I think the │ it's good to set the solver, like 'lbfgs'.   │                  │\n",
       "│ default is okay.                              │ But I think the default is okay.             │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Then, fit the model on the training data. So  │ Then, fit the model on the training data. So │                  │\n",
       "│ model.fit(X_train, y_train).                  │ model.fit(X_train, y_train).                 │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ After training, I need to predict the target  │ After training, I need to predict the target │                  │\n",
       "│ for the test set. So y_pred =                 │ for the test set. So y_pred =                │                  │\n",
       "│ model.predict(X_test).                        │ model.predict(X_test).                       │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Then, compute the confusion matrix using      │ Then, compute the confusion matrix using     │                  │\n",
       "│ confusion_matrix from sklearn.metrics. So cm  │ confusion_matrix from sklearn.metrics. So cm │                  │\n",
       "│ = confusion_matrix(y_test, y_pred).           │ = confusion_matrix(y_test, y_pred).          │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Now, I need to plot the confusion matrix. How │ Now, I need to plot the confusion matrix.    │                  │\n",
       "│ do I do that? I remember that a heatmap is a  │ How do I do that? I remember that a heatmap  │                  │\n",
       "│ good way to visualize it. So I can use        │ is a good way to visualize it. So I can use  │                  │\n",
       "│ matplotlib's imshow function, or perhaps use  │ matplotlib's imshow function, or perhaps use │                  │\n",
       "│ seaborn's heatmap for better aesthetics.      │ seaborn's heatmap for better aesthetics.     │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Wait, but the function needs to return the    │ Wait, but the function needs to return the   │                  │\n",
       "│ confusion matrix as a numpy array and the     │ confusion matrix as a numpy array and the    │                  │\n",
       "│ Axes object. So I'll need to create a plot,   │ Axes object. So I'll need to create a plot,  │                  │\n",
       "│ make it a figure, plot the confusion matrix,  │ make it a figure, plot the confusion matrix, │                  │\n",
       "│ and then return the axes.                     │ and then return the axes.                    │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ So let's outline the plotting steps:          │ So let's outline the plotting steps:         │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ 1. Create a figure and axes. Or just use      │ 1. Create a figure and axes. Or just use     │                  │\n",
       "│ plt.subplots to create a figure and axes      │ plt.subplots to create a figure and axes     │                  │\n",
       "│ object.                                       │ object.                                      │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ 2. Use sns.heatmap to plot the confusion      │ 2. Use sns.heatmap to plot the confusion     │                  │\n",
       "│ matrix. But wait, the confusion matrix is a   │ matrix. But wait, the confusion matrix is a  │                  │\n",
       "│ numpy array. However, the heatmap function    │ numpy array. However, the heatmap function   │                  │\n",
       "│ can take the data, and I can set parameters   │ can take the data, and I can set parameters  │                  │\n",
       "│ like annot=True to show the numbers, and fmt  │ like annot=True to show the numbers, and fmt │                  │\n",
       "│ to format the numbers as integers.            │ to format the numbers as integers.           │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ 3. Set the x-axis labels as 'Predicted' and   │ 3. Set the x-axis labels as 'Predicted' and  │                  │\n",
       "│ the y-axis as 'Actual'.                       │ the y-axis as 'Actual'.                      │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ 4. Also, set the title of the plot.           │ 4. Also, set the title of the plot.          │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ But wait, how do I get the axes object?       │ But wait, how do I get the axes object?      │                  │\n",
       "│ Because when I create the figure and axes, I  │ Because when I create the figure and axes, I │                  │\n",
       "│ can plot on the axes and then return them.    │ can plot on the axes and then return them.   │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Alternatively, I can create a new figure,     │ Alternatively, I can create a new figure,    │                  │\n",
       "│ plot on it, and then return the axes.         │ plot on it, and then return the axes.        │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ So putting it all together:                   │ So putting it all together:                  │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ - Split the data into training and testing    │ - Split the data into training and testing   │                  │\n",
       "│ sets.                                         │ sets.                                        │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ - Train the logistic regression model.        │ - Train the logistic regression model.       │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ - Predict on the test set.                    │ - Predict on the test set.                   │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ - Compute the confusion matrix.               │ - Compute the confusion matrix.              │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ - Create a plot with a heatmap.               │ - Create a plot with a heatmap.              │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Now, let's think about possible issues.       │ Now, let's think about possible issues.      │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ What if the target has more than two classes? │ What if the target has more than two         │                  │\n",
       "│ The confusion matrix will handle it, but the  │ classes? The confusion matrix will handle    │                  │\n",
       "│ logistic regression model is for binary       │ it, but the logistic regression model is for │                  │\n",
       "│ classification. So the target should be       │ binary classification. So the target should  │                  │\n",
       "│ binary. So I guess the function assumes that  │ be binary. So I guess the function assumes   │                  │\n",
       "│ the target is binary.                         │ that the target is binary.                   │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Another thing: when using train_test_split,   │ Another thing: when using train_test_split,  │                  │\n",
       "│ the test size is                              │ the test size is                             │                  │\n",
       "│ default&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistan… │ default&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assista… │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Ensure all required dependencies are          │ Consider switching to `random.randrange` if  │                  │\n",
       "│ installed, including joblib.&lt;|eot_id|&gt;        │ the correct solution uses it&lt;|eot_id|&gt;       │                  │\n",
       "└───────────────────────────────────────────────┴──────────────────────────────────────────────┴──────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mchosen_text                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrejected_text                               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlogits          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ <|begin_of_text|><|start_header_id|>system<|… │ <|begin_of_text|><|start_header_id|>system<… │ [0.4907, 0.5093] │\n",
       "│                                               │                                              │                  │\n",
       "│ Cutting Knowledge Date: December 2023         │ Cutting Knowledge Date: December 2023        │                  │\n",
       "│ Today Date: 07 May 2025                       │ Today Date: 07 May 2025                      │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ <|eot_id|><|start_header_id|>user<|end_heade… │ <|eot_id|><|start_header_id|>user<|end_head… │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Give me an advice to the problem and answer   │ Give me an advice to the problem and answer  │                  │\n",
       "│ below;                                        │ below;                                       │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Problem:Train a logistic regression model on  │ Problem:Train a logistic regression model on │                  │\n",
       "│ one feature and evaluate its performance      │ one feature and evaluate its performance     │                  │\n",
       "│ using a confusion matrix plot. The function   │ using a confusion matrix plot. The function  │                  │\n",
       "│ takes a feature and a target series, splits   │ takes a feature and a target series, splits  │                  │\n",
       "│ them into training and testing sets, trains   │ them into training and testing sets, trains  │                  │\n",
       "│ the logistic regression model, predicts the   │ the logistic regression model, predicts the  │                  │\n",
       "│ target for the test set, and plots the        │ target for the test set, and plots the       │                  │\n",
       "│ confusion matrix.                             │ confusion matrix.                            │                  │\n",
       "│ The function should output with:              │ The function should output with:             │                  │\n",
       "│     (np.ndarray, plt.Axes): A tuple           │     (np.ndarray, plt.Axes): A tuple          │                  │\n",
       "│ containing the confusion matrix and the       │ containing the confusion matrix and the      │                  │\n",
       "│ matplotlib Axes object of the confusion       │ matplotlib Axes object of the confusion      │                  │\n",
       "│ matrix plot.                                  │ matrix plot.                                 │                  │\n",
       "│ You should write self-contained code starting │ You should write self-contained code         │                  │\n",
       "│ with:                                         │ starting with:                               │                  │\n",
       "│ ```                                           │ ```                                          │                  │\n",
       "│ import pandas as pd                           │ import pandas as pd                          │                  │\n",
       "│ from sklearn.model_selection import           │ from sklearn.model_selection import          │                  │\n",
       "│ train_test_split                              │ train_test_split                             │                  │\n",
       "│ from sklearn.linear_model import              │ from sklearn.linear_model import             │                  │\n",
       "│ LogisticRegression                            │ LogisticRegression                           │                  │\n",
       "│ from sklearn.metrics import confusion_matrix  │ from sklearn.metrics import confusion_matrix │                  │\n",
       "│ import numpy as np                            │ import numpy as np                           │                  │\n",
       "│ import matplotlib.pyplot as plt               │ import matplotlib.pyplot as plt              │                  │\n",
       "│ def task_func(feature: pd.Series, target:     │ def task_func(feature: pd.Series, target:    │                  │\n",
       "│ pd.Series) -> (np.ndarray, plt.Axes):         │ pd.Series) -> (np.ndarray, plt.Axes):        │                  │\n",
       "│ ```                                           │ ```                                          │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Answer:<think>                                │ Answer:<think>                               │                  │\n",
       "│ Okay, I need to write a Python function       │ Okay, I need to write a Python function      │                  │\n",
       "│ called task_func that takes a feature and a   │ called task_func that takes a feature and a  │                  │\n",
       "│ target as inputs and returns a tuple          │ target as inputs and returns a tuple         │                  │\n",
       "│ containing a confusion matrix and a           │ containing a confusion matrix and a          │                  │\n",
       "│ matplotlib Axes object. The function should   │ matplotlib Axes object. The function should  │                  │\n",
       "│ train a logistic regression model on one      │ train a logistic regression model on one     │                  │\n",
       "│ feature and evaluate its performance using a  │ feature and evaluate its performance using a │                  │\n",
       "│ confusion matrix plot.                        │ confusion matrix plot.                       │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ First, I should think about the steps         │ First, I should think about the steps        │                  │\n",
       "│ involved. Let's break it down.                │ involved. Let's break it down.               │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ The function starts by importing necessary    │ The function starts by importing necessary   │                  │\n",
       "│ libraries, which are already provided. So I   │ libraries, which are already provided. So I  │                  │\n",
       "│ don't need to worry about that.               │ don't need to worry about that.              │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ The first step is to split the feature and    │ The first step is to split the feature and   │                  │\n",
       "│ target into training and testing sets. I      │ target into training and testing sets. I     │                  │\n",
       "│ remember that the train_test_split function   │ remember that the train_test_split function  │                  │\n",
       "│ from sklearn can do this. So I'll use that.   │ from sklearn can do this. So I'll use that.  │                  │\n",
       "│ The feature is a pandas Series, so I need to  │ The feature is a pandas Series, so I need to │                  │\n",
       "│ convert it into a DataFrame or maybe just an  │ convert it into a DataFrame or maybe just an │                  │\n",
       "│ array? Wait, no. Wait, the feature is a       │ array? Wait, no. Wait, the feature is a      │                  │\n",
       "│ single feature, right? So when I split, I can │ single feature, right? So when I split, I    │                  │\n",
       "│ pass the feature as X and target as y.        │ can pass the feature as X and target as y.   │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Wait, but train_test_split expects X and y to │ Wait, but train_test_split expects X and y   │                  │\n",
       "│ be arrays. So for the feature, perhaps I      │ to be arrays. So for the feature, perhaps I  │                  │\n",
       "│ should convert the pd.Series into a numpy     │ should convert the pd.Series into a numpy    │                  │\n",
       "│ array. Because when I pass a Series to        │ array. Because when I pass a Series to       │                  │\n",
       "│ train_test_split, it might work, but          │ train_test_split, it might work, but         │                  │\n",
       "│ sometimes it's better to convert it to a      │ sometimes it's better to convert it to a     │                  │\n",
       "│ numpy array. Alternatively, I can reshape it  │ numpy array. Alternatively, I can reshape it │                  │\n",
       "│ into a 2D array since scikit-learn expects 2D │ into a 2D array since scikit-learn expects   │                  │\n",
       "│ for features.                                 │ 2D for features.                             │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Wait, the feature is a single feature, so     │ Wait, the feature is a single feature, so    │                  │\n",
       "│ it's a 1D array. So when I pass it to         │ it's a 1D array. So when I pass it to        │                  │\n",
       "│ train_test_split, I need to make sure it's in │ train_test_split, I need to make sure it's   │                  │\n",
       "│ the correct shape. So perhaps I should        │ in the correct shape. So perhaps I should    │                  │\n",
       "│ reshape it into a 2D array with shape         │ reshape it into a 2D array with shape        │                  │\n",
       "│ (n_samples, 1). Because LogisticRegression    │ (n_samples, 1). Because LogisticRegression   │                  │\n",
       "│ can handle that.                              │ can handle that.                             │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ So, for X, I'll take                          │ So, for X, I'll take                         │                  │\n",
       "│ feature.values.reshape(-1, 1), and y is       │ feature.values.reshape(-1, 1), and y is      │                  │\n",
       "│ target.values.                                │ target.values.                               │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Then, split them into training and testing    │ Then, split them into training and testing   │                  │\n",
       "│ sets. I can set a random state for            │ sets. I can set a random state for           │                  │\n",
       "│ reproducibility, but it's not specified, so   │ reproducibility, but it's not specified, so  │                  │\n",
       "│ maybe I can leave it out or set it to a       │ maybe I can leave it out or set it to a      │                  │\n",
       "│ specific value like 42 for consistency.       │ specific value like 42 for consistency.      │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Next, I need to train the logistic regression │ Next, I need to train the logistic           │                  │\n",
       "│ model. So I'll create an instance of          │ regression model. So I'll create an instance │                  │\n",
       "│ LogisticRegression. The default parameters    │ of LogisticRegression. The default           │                  │\n",
       "│ should be fine, but sometimes it's good to    │ parameters should be fine, but sometimes     │                  │\n",
       "│ set the solver, like 'lbfgs'. But I think the │ it's good to set the solver, like 'lbfgs'.   │                  │\n",
       "│ default is okay.                              │ But I think the default is okay.             │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Then, fit the model on the training data. So  │ Then, fit the model on the training data. So │                  │\n",
       "│ model.fit(X_train, y_train).                  │ model.fit(X_train, y_train).                 │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ After training, I need to predict the target  │ After training, I need to predict the target │                  │\n",
       "│ for the test set. So y_pred =                 │ for the test set. So y_pred =                │                  │\n",
       "│ model.predict(X_test).                        │ model.predict(X_test).                       │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Then, compute the confusion matrix using      │ Then, compute the confusion matrix using     │                  │\n",
       "│ confusion_matrix from sklearn.metrics. So cm  │ confusion_matrix from sklearn.metrics. So cm │                  │\n",
       "│ = confusion_matrix(y_test, y_pred).           │ = confusion_matrix(y_test, y_pred).          │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Now, I need to plot the confusion matrix. How │ Now, I need to plot the confusion matrix.    │                  │\n",
       "│ do I do that? I remember that a heatmap is a  │ How do I do that? I remember that a heatmap  │                  │\n",
       "│ good way to visualize it. So I can use        │ is a good way to visualize it. So I can use  │                  │\n",
       "│ matplotlib's imshow function, or perhaps use  │ matplotlib's imshow function, or perhaps use │                  │\n",
       "│ seaborn's heatmap for better aesthetics.      │ seaborn's heatmap for better aesthetics.     │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Wait, but the function needs to return the    │ Wait, but the function needs to return the   │                  │\n",
       "│ confusion matrix as a numpy array and the     │ confusion matrix as a numpy array and the    │                  │\n",
       "│ Axes object. So I'll need to create a plot,   │ Axes object. So I'll need to create a plot,  │                  │\n",
       "│ make it a figure, plot the confusion matrix,  │ make it a figure, plot the confusion matrix, │                  │\n",
       "│ and then return the axes.                     │ and then return the axes.                    │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ So let's outline the plotting steps:          │ So let's outline the plotting steps:         │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ 1. Create a figure and axes. Or just use      │ 1. Create a figure and axes. Or just use     │                  │\n",
       "│ plt.subplots to create a figure and axes      │ plt.subplots to create a figure and axes     │                  │\n",
       "│ object.                                       │ object.                                      │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ 2. Use sns.heatmap to plot the confusion      │ 2. Use sns.heatmap to plot the confusion     │                  │\n",
       "│ matrix. But wait, the confusion matrix is a   │ matrix. But wait, the confusion matrix is a  │                  │\n",
       "│ numpy array. However, the heatmap function    │ numpy array. However, the heatmap function   │                  │\n",
       "│ can take the data, and I can set parameters   │ can take the data, and I can set parameters  │                  │\n",
       "│ like annot=True to show the numbers, and fmt  │ like annot=True to show the numbers, and fmt │                  │\n",
       "│ to format the numbers as integers.            │ to format the numbers as integers.           │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ 3. Set the x-axis labels as 'Predicted' and   │ 3. Set the x-axis labels as 'Predicted' and  │                  │\n",
       "│ the y-axis as 'Actual'.                       │ the y-axis as 'Actual'.                      │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ 4. Also, set the title of the plot.           │ 4. Also, set the title of the plot.          │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ But wait, how do I get the axes object?       │ But wait, how do I get the axes object?      │                  │\n",
       "│ Because when I create the figure and axes, I  │ Because when I create the figure and axes, I │                  │\n",
       "│ can plot on the axes and then return them.    │ can plot on the axes and then return them.   │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Alternatively, I can create a new figure,     │ Alternatively, I can create a new figure,    │                  │\n",
       "│ plot on it, and then return the axes.         │ plot on it, and then return the axes.        │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ So putting it all together:                   │ So putting it all together:                  │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ - Split the data into training and testing    │ - Split the data into training and testing   │                  │\n",
       "│ sets.                                         │ sets.                                        │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ - Train the logistic regression model.        │ - Train the logistic regression model.       │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ - Predict on the test set.                    │ - Predict on the test set.                   │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ - Compute the confusion matrix.               │ - Compute the confusion matrix.              │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ - Create a plot with a heatmap.               │ - Create a plot with a heatmap.              │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Now, let's think about possible issues.       │ Now, let's think about possible issues.      │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ What if the target has more than two classes? │ What if the target has more than two         │                  │\n",
       "│ The confusion matrix will handle it, but the  │ classes? The confusion matrix will handle    │                  │\n",
       "│ logistic regression model is for binary       │ it, but the logistic regression model is for │                  │\n",
       "│ classification. So the target should be       │ binary classification. So the target should  │                  │\n",
       "│ binary. So I guess the function assumes that  │ be binary. So I guess the function assumes   │                  │\n",
       "│ the target is binary.                         │ that the target is binary.                   │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Another thing: when using train_test_split,   │ Another thing: when using train_test_split,  │                  │\n",
       "│ the test size is                              │ the test size is                             │                  │\n",
       "│ default<|eot_id|><|start_header_id|>assistan… │ default<|eot_id|><|start_header_id|>assista… │                  │\n",
       "│                                               │                                              │                  │\n",
       "│ Ensure all required dependencies are          │ Consider switching to `random.randrange` if  │                  │\n",
       "│ installed, including joblib.<|eot_id|>        │ the correct solution uses it<|eot_id|>       │                  │\n",
       "└───────────────────────────────────────────────┴──────────────────────────────────────────────┴──────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='2205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  24/2205 06:03 < 10:01:09, 0.06 it/s, Epoch 0.03/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.339076</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.230500</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.418800</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.627400</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.531700</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.303600</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.242800</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.193100</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.351100</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.148900</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.521500</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.198100</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import RewardConfig\n",
    "from peft import LoraConfig, TaskType\n",
    "\n",
    "batch_size_per_device = 4\n",
    "eval_batch_size_per_device = 4\n",
    "\n",
    "training_args = RewardConfig(\n",
    "    output_dir=model_save_dir,\n",
    "    per_device_train_batch_size=batch_size_per_device,\n",
    "    per_device_eval_batch_size=eval_batch_size_per_device,\n",
    "    #evaluation_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    eval_on_start=True,\n",
    "    save_steps=20,\n",
    "    logging_steps=1,\n",
    "    num_train_epochs = 3,\n",
    "    report_to=None,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    target_modules=[\"k_proj\",\"q_proj\",\"o_proj\", \"v_proj\",\"down_proj\",\"gate_proj\",\"up_proj\",],\n",
    "    layers_to_transform=[25,26,27],\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "\n",
    "rmtrainer.train(formatted_dataset, training_args = training_args, peft_config = peft_config)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
